{"version":3,"sources":["../../../src/lib/genlex/tokenizer.js"],"names":["keywords","Tokenizer","parser","generator","tokens","builder","charstream","parse","toTry"],"mappings":";;;;;;qjBAAA;;;;;;;;kBAuBe,UAASA,QAAT,EAAmB;AAC9B,WAAO,IAAIC,SAAJ,CAAcD,QAAd,CAAP;AACH,C;;AAjBD;;;;AACA;;;;;;;;IAEMC,S;AACF;AACA,uBAAYD,QAAZ,EAAsB;AAAA;;AAClB,aAAKE,MAAL,GAAc,iBAAOC,SAAP,CAAiBH,QAAjB,EAA2BI,MAA3B,CAAkC,gBAAMC,OAAxC,CAAd;AACH;;AAED;;;;;iCACSC,U,EAAY;AACjB,mBAAO,KAAKJ,MAAL,CAAYK,KAAZ,CAAkBD,UAAlB,EAA8B,CAA9B,EAAiCE,KAAjC,EAAP;AACH","file":"tokenizer.js","sourcesContent":["/*\r\n * Parsec\r\n * https://github.com/d-plaindoux/parsec\r\n *\r\n * Copyright (c) 2016 Didier Plaindoux\r\n * Licensed under the LGPL2 license.\r\n */\r\n\r\nimport genlex from './genlex';\r\nimport token from './token';\r\n\r\nclass Tokenizer {\r\n    // [String] -> Tokenizer\r\n    constructor(keywords) {\r\n        this.parser = genlex.generator(keywords).tokens(token.builder);\r\n    }\r\n\r\n    // Stream char -> Try [Token]\r\n    tokenize(charstream) {\r\n        return this.parser.parse(charstream, 0).toTry();\r\n    }\r\n}\r\n\r\nexport default function(keywords) {\r\n    return new Tokenizer(keywords);\r\n}\r\n"]}