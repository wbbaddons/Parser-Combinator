{"version":3,"sources":["../../../src/lib/genlex/tokenizer.js"],"names":["keywords","Tokenizer","parser","generator","tokens","builder","charstream","parse","toTry"],"mappings":";;;;;;qjBAAA;;;;;;;;kBAuBe,UAASA,QAAT,EAAmB;AAC9B,WAAO,IAAIC,SAAJ,CAAcD,QAAd,CAAP;AACH,C;;AAjBD;;;;AACA;;;;;;;;IAEMC,S;AACF;AACA,uBAAYD,QAAZ,EAAsB;AAAA;;AAClB,aAAKE,MAAL,GAAc,iBAAOC,SAAP,CAAiBH,QAAjB,EAA2BI,MAA3B,CAAkC,gBAAMC,OAAxC,CAAd;AACH;;AAED;;;;;iCACSC,U,EAAY;AACjB,mBAAO,KAAKJ,MAAL,CAAYK,KAAZ,CAAkBD,UAAlB,EAA8B,CAA9B,EAAiCE,KAAjC,EAAP;AACH","file":"tokenizer.js","sourcesContent":["/*\n * Parsec\n * https://github.com/d-plaindoux/parsec\n *\n * Copyright (c) 2016 Didier Plaindoux\n * Licensed under the LGPL2 license.\n */\n\nimport genlex from './genlex';\nimport token from './token';\n\nclass Tokenizer {\n    // [String] -> Tokenizer\n    constructor(keywords) {\n        this.parser = genlex.generator(keywords).tokens(token.builder);\n    }\n\n    // Stream char -> Try [Token]\n    tokenize(charstream) {\n        return this.parser.parse(charstream, 0).toTry();\n    }\n}\n\nexport default function(keywords) {\n    return new Tokenizer(keywords);\n}\n"]}